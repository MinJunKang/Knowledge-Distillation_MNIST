# Knowledge-Distillation_MNIST
Single Teacher to Single Student model knowledge distillation using DNN Structure

# Data
MNIST - Tensorflow

# Usage
in the console type 'python3 Python_code.py'

You'll have to choose 3 options

First, you have to choose the option 1 to train the Teacher Model. The data will be saved at 'checkpoint' dir and 'logs' dir

Second, you have to choose the option 2 or 3 to train the Student Model. 
  Option 2 is just training Student Model without using the soft target of Teacher model
  Option 3 is training Student Model with using the soft target of Teacher model
  
# Programming Language
Python 3.6
Tensorflow
